# 14장 - 유튜브 설계

앞에나오는 설명 주절주절.. 정리하면

![Untitled](https://github.com/organization-for-study/study-system-design-interview/assets/97773895/036e7a25-0d2c-4516-8323-9d4f87c16b14)


---

## 유튜브(영상 스트리밍서비스) 설계 핵심

1. 다양한 디바이스 지원 : 앱, 브라우저, TV
2. 원활한 비디오 재생
3. 비디오 품질선택
4. 빠른 비디오 업로드
5. 이 모든걸 수용한 낮은 인프라비용

---

## 1.  다양한 디바이스 지원 : 앱, 브라우저, TV

> **우리는 유튜브 영상을 스마트폰 앱, 브라우저, TV등 다양한 디바이스에서 시청한다.
어떻게 여러 환경에서 영상이 실행되는걸까?**
> 
> 
> ---
> <img width="362" alt="Untitled 1" src="https://github.com/organization-for-study/study-system-design-interview/assets/97773895/4b4010b8-a725-4164-a014-2aae10beb8e8">
> 
> **Q1.  어떻게 여러 사용자 단말기에서 하나의 영상을 문제없이 볼 수 있을까?**
> 
> **A1. 스트리밍 프로토콜로 적응형 스트리밍 기술을 사용한다.**
> 스트리밍 프로토콜은 다양한 디바이스에서 영상을 실시간으로 원활한 재생을 위해 
> 적절한 품질의 영상을 전송하는 역할을 한다. 
> 프로토콜마다 지원하는 비디오 인코딩이다르고 소프트웨어(앱)도 다르다.
> 유튜브는 적적한 프로토콜을 1~n 개를 선택하여 사용자에게 최적의 스트리밍을 제공한다.
> 
> - 프로토콜 종류
>     - MPEG_DASH
>     - HLS
>     - Microsoft Smooth Streaming
>     - HDS
> 
> ---
> 
> **Q2. 스트리밍 프로토콜로 적절 영상을 전송하는데… 그럼 영상이 여러개인건가?**
> 
> **A2. 트랜스코딩은** 하나의 **영상을 여러가지 버전으로 변환**하여 **저장**합니다.
> 
> 트랜스코딩은 다양한 형식과 품질의 비디오를 만들어내는 과정이다.
> 유튜브는 업로드된 동영상을 여러 형식과 해상도로 트랜스코딩한다.
> 
> - **다양한 해상도 :** 
> 고해상도(예: 1080p), 중간 해상도(예: 720p), 저해상도(예: 480p) 등으로 변환
> - **다른 비트레이트 :** 
> 여러가지 해상도 버전은 다시 여러 비트레이트 옵션으로 변환
> 사용자의인터넷 속도에 따라 최적화된 스트리밍 품질을 제공할 수 있음.
> - **코덱변환 :** 
> H.264, VP9, HEVC 등 으로 비디오를 인코딩한다.
>  다양한 플랫폼 및 디바이스 호환성을 보장됨.
> 
> ---
> 
> ***비트레이트 :** 
> **데이터 전송 속도를 나타내는 척도**이며, **'초당 전송되는 데이터의 양'**을 의미한다.
> 고화질은 비트의 수가 높으며, 높은 화질은 빠른 처리가 필요하기 때문에 
> 인터넷 속도가 높아야한다.  인코딩할 때, 해상도에 적절한 비트레이트 값을 설정해야함.
> 
> - 해상도(high) - 비트레이트(low) = 초당 전송되는 속도가 낮아서 화면이 뭉개짐
> - 해상도(low) - 비트레이트(high) = 해상도 대비 전송되는 데이터값만 커짐
> 
> ***코덱 :** 
> .h264같은 압축된 영상 및오디오 파일들
> 
> ---
> 
> **[상황 예시]**
> 즉, 트랜스코딩은 다양한 디바이스에서 비디오를 재생할 수 있게 만드는 
> 첫 단계로, 비디오를 여러 가지 형식과 품질로 변환한다.
> 변환된 비디오들은 스트리밍 프로토콜을 통해 네트워크 상태와 디바이스 성능에 
> 적합한 방식으로 사용자에게 전송됩니다. ( = **적응형 스트리밍** )
> 
> 예를 들어, 
> 사용자의 인터넷 속도가 빠르고 고해상도 디스플레이를 가진 디바이스를 사용하는 경우!
> 현대에 주로스트리밍 프로토콜은 고화질 비디오를 전송할 것이다. 
> 반면 속도가 느리거나 낮은 해상도의 디스플레이를 사용하는 경우에는 낮은 품질의 비디오를 전송합니다.
> 


## 2. 원활한 비디오 재생

> **유튜브를 재상 버튼을 눌렀을때 바로 재생된다.
유튜브본사는 캘리포니아고, 유튜브는 동접자도 많으며, 영상도 길게는 몇시간의 영상도 있다.
영상 재생시 어떻게 이렇게 빨리 재생될까?**
> 
> 
> ---
> 
> **Q1. 외국 서버의 데이터가 이토록 빠른 서비스를 제공하는 방법은?**
> **A1. CDN(Content Delivery Network)를 적극 이용한다.**
> 
> <img width="313" alt="Untitled 2" src="https://github.com/organization-for-study/study-system-design-interview/assets/97773895/c7deab11-90bb-437f-9992-d2eb19add3e9">
> 
> 비디오는 CDN에 저장되어져 있다. 우리가 비디오 재생시 
> 가장 가까운 에지 서버(edge server)에서 스트리밍이 이루어진다.
> 유튜브 규모의 다양한 글로벌 시장의 해외기업들이흔히 사용하는 방법이다.
> 그리고 **인기있는 동영상은 전 세계에 여러 CDN 서버에 복제**되어 
> 많은 사람들이 동시에 접근하더라도 트래픽에 부담없이 원활한 시청이 가능하다.
>
> <img width="441" alt="Untitled 3" src="https://github.com/organization-for-study/study-system-design-interview/assets/97773895/9099b105-0257-49cb-940f-cf55911e39c0">
> 
> 그리고 스트리밍을 제외한 나머지 요청은 API서버가 처리한다.
> 
> ---
> 
> **Q2. 영상 시청시 보이는 로딩바는 뭘까?**
> **A2. 클라이언트는 영상을 재생하는 동시에 영상을 다운로드하고 버퍼에 추가한다.**
> 
>![Untitled 4](https://github.com/organization-for-study/study-system-design-interview/assets/97773895/fab32ff1-ebe4-45c5-ac15-5fc647f37b50)
> 
> 동시 다운로드 및 재생이 가능한 이유는 영상 데이터가 **HLS(HTTP Live Streaming),
> Dynamic Adaptive Streaming over HTTP (DASH)** 같은 적응형 스트리밍 프로토콜을 사용하여 여러 개의 작은 조각(=세그먼트)으로 나누어져 전송되기 때문이다.
> 
> 위에 트랜스코딩에 대해 언급한 적이있는데, 원본영상을 일정한 간격으로 세트먼팅하고
> 병렬적으로 트랜스 코딩을 수행해서 저장하는듯하다.
> 
> 무튼 이렇게 나누어진 영상을 재생과 동시에 다운받음으로써 사용자는
> 영상을 볼 때 영상이 완전히 다운로드 된 후 재생하는 불편함없이
> 시청과 동시에 재생을 할 수 있다.
> 
>
> **[상황 예시]**
>  즉, 싸이의 강남스타일뮤비가 전세계적으로 핫해진건. 외국에서 강남 스타일의
> 뷰어가 점점 많아지자 유튜브는 트래픽을 분석 후, 전 세계 CDN 에지서버에 캐싱했을 것이다.
> 
> 해당 비디오가 아직 그 서버에 캐싱되지 않았다면, 첫 번째 시청자는 
> CDN의 원본 서버로부터 비디오를 스트리밍 받았을것이다.
> 첫 번째 시청자는 버퍼링을 경험할 수 있을것이다.(아마도.. 인터넷환경에 따라 바뀔 수 있음)
> 
> 그 후에 유튜브 정책에 따라 짧은 기간동안 에지서버에 캐싱되어있고,
> 호출 트래픽에 따라 캐싱기간을 길게 했을 수 도 있다.
> 


## 3. 비디오 업로드

> 유튜브 영상의 갯수는 2006년 에만 2500만건을 넘었고, 
하루 2만개의 업로드가 이루어졌다고 기록되어있으니..

책에서는 신규 비디오 저장을 위해 매일 150TB를 요구할 정도로 엉청난 규모의
영상이 저장되고 업로드된다.

비용을 생각기전에,  어떻게 이렇게 많은 영상 업로드가 이뤄지는걸까?
> 
> 
> ---
> 
> **Q1. 업로드는 요청은 어디서 이루어질까?**
> **A1. 업로드는 API서버에서 요청받아 처리한다.**
> 
> ![Untitled 5](https://github.com/organization-for-study/study-system-design-interview/assets/97773895/03ad5d90-05e5-45d3-8c4d-237be518177a)
> 
> CDN은  빠르게 전송하기위해 저장하는곳이며, 업로드를 포함한 다른 요청은
> API서버에서 처리한다. 그렇담 더 복잡한 아키텍쳐와 컴포넌트를 이용해서 업로드를 처리한다.
> 
> - **로드밸런서 (load balancer) :** 요청 분산처리
> - **API 서버 :** 요청 처리
> - **메타데이터 데이터베이스(metadata DB) :** 비디오 메타정보 보관(샤딩/다중화 적용)
> - **메타데이터 캐시(metadata cache) :** 메타데이터와 사용자정보를 캐시 (성능 효율적 향상 목적)
> - **원본 저장소(orginal storage) :** 원본비디오 저장 ( 대형 이진 파일 저장소 : BLOB )
> - **트랜스코딩 서버 (transcoding server) :** 영상 인코딩 ( 스트리밍을 위해서 필요 )
> - **트랜스코딩비디오 저장소 :**  트랜스코딩 완료후 BLOB저장소(후에CDN이동)
> - **CDN :** 스트리밍을 위해 비디오 캐시 담당
> - **트랜스코딩 완료 큐( completion queue ) :** 트랜스코딩 완료 이벤트를 보관
> - **트랜스코딩 완료 핸들러(completion handler) :** 
> 트랜스코딩 완료 큐에서 이벤트데이터를 메타데이터 캐시와 데이터베이스를
> 갱신하는 작업을 하는 서버들
> 
> ---
> 
> **Q2. 내가 올린 업로드가 스트리밍 가능하기까지 어떤 흐름을 갖고있을까?**
> **A2. 첫번째 질문에서 나온 컴포넌트들이 다같이 처리해줌.**
> 
> ![Untitled 6](https://github.com/organization-for-study/study-system-design-interview/assets/97773895/42a1e527-066f-4d6f-9e79-850998af6c04)
> 
> 1. 비디오를 원본 저장소에 업로드한다.
> 2. 트랜스코딩 서버는 원본 저장소에서 해당 비디오를 가져와 트랜스코딩을 시작한다.
> 3. 트랜스코딩이 완료되면 아래 두 절차가 병렬적으로 수행된다.
>     
>     3a. 완료된 비디오를 트랜스코딩 비디오 저장소로 업로드한다
>     
>     3a.1. 트랜스코딩이 끝난 비디오를 CDN에 올린다 
>     
>     3b. 트랜스코딩 완료 이벤트를 트랜스코딩 완료 큐에 넣는다
>     
>     3b.1.완료 핸들러가 이벤트 데이터를 큐에서 꺼낸다
>     
>     3b1.a. / 3b.1.b.완료 핸들러가 메타데이터 데이터베이스와 캐시를 갱신한다.
>     
> 4. API 서버가 단말에게 업로드가 끝나서 스트리밍 준비가 되었음을 알려줌.
> 
> **Q3. 이렇게 많은 과정에서 시간이 너무 길게 발생하지않을까?**
> 
> **A3-1. 속도 최적화 : 모든 절차를 병렬화한다.**
> 
> ![Untitled 7](https://github.com/organization-for-study/study-system-design-interview/assets/97773895/dfa69623-7f3b-4d0f-9d22-ace3b7d4483e)
> 
> 원본 저장소에서 CDN 까지 옮기는 절차를 메시지큐를 도입하여, 
> 시스템간의 결합도를 낮출 수 있다.
> 각 모듈들은 이전 모듈의 작업이 끝날때 까지 기다리지않고
> 메시지 큐에서 꺼내서 쓸 수 있다.
> 
> **A3. 비디오 트랜스코딩시 DAG모델 사용**
> 
>![Untitled 8](https://github.com/organization-for-study/study-system-design-interview/assets/97773895/1227b4cf-3f38-43a8-aa0b-938e9dd27dc0)
> 
> 영상마다 비디오인코딩작업이 다르기때문에 비디오를 트랜스코딩할 때
> 자원과 시간소모가 크다. 
> 트랜스코딩 할 때 도 DAG모델을 도입해서, 병렬적으로 사용할 수 있다.
> 
> - 비디오 / 오디오 / 메타데이터 3가지로 나눔
> - 비디오 인코딩 / 오디오 인코딩 / 메타데이터 추출을 병렬적으로 작업
> - 병합
> 
> **[상황 예시]**
> 
> 우리가 영상을 업로드한다고 생각해보자. 
> 
> 1. 원본영상이 일단 저장소로 이동된다.
> 2. 원본 저장소의 영상을 트랜스코딩서버에서 처리한다.
> 3. 트랜스코딩을하며, 호환성과 품질, 비트레이트를 갖춘 여러버전의 영상으로 변환된다.
> 4. 이때, DAG(비순환 그래프)모델을 이용하여, 병렬적으로 인코딩한다.
> 5. 완료된 인코딩영상은 트랜스코딩 저장소로 이동된다.
> 6. 그리고 적절한 에지서버에 배치된다.
> 7. 1~6번의 과정들은 메시지큐를 이용해서 여러요청을 빠르게 처리할 수 있다.
> 


## 4.  비용

> 글로벌 대규모 스트리밍 서비스는 특히나 많은 비용을 발생한다.
가장 크리티컬한 비용은 CDN이다.(계략적 추정에서도 언급됨)
> 
> 
> ---
> 
> 1. 인기가없는 짧은 비디오는 원본그대로 뒀다가 필요 할 때 인코딩하여 재생
> 2. 인기가 많은 비디오는 CDN을 통해 재생하고 그밖에 비디오는 서버에서 재생
> 3. 특정 지역에서 인기가많은 비디오는 해당 국가와 가까운 에지 서버에만 배치
> 4. CDN을 직접 구축하고 인터넷 서비스 제공자(ISP)와 제휴
> 5. 264, VP9, HEVC 등 으로 비디오를 인코딩한다.
>
