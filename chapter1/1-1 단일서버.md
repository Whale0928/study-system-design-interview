### **1 - 1.  단일서버**

> 웹, 앱 데이터베이스, 캐시 등 전부 서버 한 대에서 실행된다.
> 

<img width="369" alt="스크린샷 2023-11-26 오후 3 02 43" src="https://github.com/organization-for-study/study-system-design-interview/assets/97773895/c9dbf2e8-2a93-4518-8dde-16e74f092730">


1. 사용자는 웹 브라우저나 모바일 앱을 통해 도메인 이름(예: [www.mysite.com](http://www.mysite.com/), api.mysite.com)으로 웹사이트에 접속을 시도합니다.
2. 웹사이트의 도메인 이름은 DNS(Domain Name System) 조회를 통해 해당 웹 서버의 IP 주소로 변환됩니다.
3. 변환된 IP 주소로 사용자의 디바이스는 HTTP 요청을 전송합니다.
4. 웹 서버는 이 HTTP 요청을 받고, 요청된 데이터를 HTML 또는 JSON형식의 문서로 반환하여 사용자에게 응답합니다.

이 과정은 인터넷 상에서 정보를 찾고, 데이터를 주고받는 기본적인 흐름을 잘 나타내고 있는 단일서버 구조입니다.

---

단일서버는 하나의 서버만을 사용하는 가장 기본적인 시스템 구성 방식입니다.

- 구성이 간단하고 관리가 용이하다.
- 초기 비용이 상대적으로 낮다.

하지만, 단일서버 구성은 여러 한계점을 가지고 있습니다.

- **트래픽 처리 능력**: 많은 사용자가 동시에 접근할 때, 단일 서버는 트래픽을 효과적으로 처리하는 데 한계가 있습니다.
- **가용성 한계 :** 서비스 제공자가 사용자에게 보장하는 성능중 하나입니다. 가용성의 부족은 단일서버 구성의 큰 단점 중 하나입니다. 높은 가용성을 달성하기 위한 설계시 고려되어야 할 것들이 있습니다.

---

여담으로 단일서버는 1990년대~2000년 초반에 인터넷 서비스퀄리티와 사용자가 낮을때 주로 이용되었습니다.(요즘도 사용하긴함)

정보가 없어 정확하진않지만 추측해봤을때, 

2004년에 마크 주커버그가 하버드 대학교 기숙사 방에서 시작했습니다. 당시 페이스북은 하버드 대학생들 만사용했었고, 기능도 지금보다 단순했습니다. 당시에 클라우드 서비스가 오늘날처럼 발달아지 않았기에 단일서버 데이터베이스를 사용한 서비스를 운영했을 가능성이 있어 단일서버를 사용했다고 개인적으로 추측했습니다.

단일 서버 환경에서 운영하는 것은 트래픽이 많지 않고, 데이터 처리 요구사항이 상대적으로 낮은 애플리케이션에 적합합니다. 그러나 사용자 기반의 확장, 데이터의 증가, 고가용성과 재해 복구 요구사항과 같은 요소들은 분산 데이터베이스 시스템이나 클라우드 기반 솔루션으로의 전환을 필요로 할 수 있습니다.

그리고 역시나 1년 뒤.. 2005년 페이스북이 악셀 파트너스(Accel Partners)로부터 첫 대규모 투자를 받은 후, 그들은 서버와 인프라를 확장하기 시작했습니다.
사용자 기반이 백만을 넘어서고 더 많은 대학교가 서비스에 추가됨에 따라, 페이스북은 데이터 센터를 임대하고, 자체 서버를 구축하며, 트래픽을 처리하기 위한 더욱 강력한 하드웨어와 소프트웨어 솔루션을 도입했고 오늘날의 메타가 됐습니다.

1년뒤인 2005년 악셀 파트너스(Accel Partners)로부터의 투자 이후, 페이스북은 규모 확장을 위해 데이터 센터를 임대하고 자체 서버를 구축하기 시작했습니다. 사용자 기반이 백만을 넘어서고 더 많은 서비스가 추가되면서, 페이스북은 트래픽 처리와 데이터 관리를 위해 더 강력한 하드웨어와 소프트웨어 솔루션을 도입했습니다. 

하버드생이 만든 소규모의 서비스가 투자를 바탕으로 서비스 사용자 규모에 따른 확장을 하며 오늘날의 메타가 된 것은, 단일서버구성을 보완하기 위해 여러 대안적인 시스템 아키텍처들로 설계를 확장-구축한 사례로 볼 수 있습니다.


![fb](https://github.com/organization-for-study/study-system-design-interview/assets/97773895/18f0da6d-89bd-4bc5-b5d0-bc8172446129)


### **1-2. 시스템 설계 아키텍쳐로 인한 규모 확장**

위 페이스북 사례처럼 서비스가 확장되며 규모가 커지지게된다면 단일 서버 구성의 한계를 넘어서면 여러 시스템 아키텍처를 사용하게 됩니다. 1장에서는 점차 확장되는 시스템 아키텍쳐 구성들을 보여주고 있습니다.

DNS (Domain Name System), CDN (Content Delivery Network), 로드 밸런서(Load Balancer), 데이터베이스 샤딩(Database Sharding), 캐시(Cache), NoSQL / SQL 데이터베이스 등을 이용하여 1장 전반적으로 “사용자 수에따른 규모 확장성”을 단계적으로 설명해주고 있습니다.

(1장 후반부의 42페이지의 이미지를 첨부 - 이렇게 확장됩니다.)

<img width="429" alt="스크린샷 2023-11-26 오후 3 05 17" src="https://github.com/organization-for-study/study-system-design-interview/assets/97773895/d8fdc6c9-82fa-44bc-ac29-df7bd31f6627">

### **1-2. 시스템 설계 아키텍쳐로 인한 규모 확장**

위 페이스북 사례처럼 서비스가 확장되며 규모가 커지지게된다면 단일 서버 구성의 한계를 넘어서면 여러 시스템 아키텍처를 사용하게 됩니다. 1장에서는 점차 확장되는 시스템 아키텍쳐 구성들을 보여주고 있습니다.

DNS (Domain Name System), CDN (Content Delivery Network), 로드 밸런서(Load Balancer), 데이터베이스 샤딩(Database Sharding), 캐시(Cache), NoSQL / SQL 데이터베이스 등을 이용하여 1장 전반적으로 “사용자 수에따른 규모 확장성”을 단계적으로 설명해주고 있습니다.

(1장 후반부의 42페이지의 이미지를 첨부 - 이렇게 확장됩니다.)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/43abd0ae-735e-4218-a0e8-8ee2927505ff/3b238a38-7e8b-4519-a679-2f4ce2acf568/Untitled.png)

### 2-1. 데이터베이스

> 웹/모바일 트래픽 처리서버(웹계층)과 데이터 서버(데이터계층) 을 분리하여 늘어난 사용자에게 서비스의 가용성을 확대할 수 있다.
> 

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/43abd0ae-735e-4218-a0e8-8ee2927505ff/2d43ab92-e061-43ec-8fb8-bdb24d688f37/Untitled.png)

관계형 데이터베이스(Relational Database)와 비관계형 데이터베이스(NoSQL Database)로 크게 두 가지로 나눌 수 있습니다. 

- **관계형 데이터베이스(RDBMS)**:
    - 데이터를 테이블 형태로 저장합니다.
    - 테이블 간의 관계를 통해 데이터를 조직화합니다.
    - SQL(Structured Query Language)을 사용하여 데이터를 관리합니다.
- **비관계형 데이터베이스(NoSQL)**:
    - 키-값 쌍, 문서, 그래프, 컬럼 패밀리 등 다양한 데이터 모델을 사용합니다.
    - 관계형 모델에 비해 유연성이 높습니다.(관계형이 아니니까)
    - JSON, YAML, XML 등의 응답/요청의 직렬/역직렬이 효율적입니다.
    *문서 지향형 데이터베이스는 JSON, XML 또는 유사한 포맷이라서
    - 유연한 스키마로 많은 양의 데이터를 저장하기에 좋습니다.
    *유연한 스키마(Flexible Schema)란?
    데이터베이스가 데이터의 구조를 미리 엄격하게 정의하지 않고, 데이터가 입력될 때 구조가 결정되거나 변경될 수 있는 방식을 말합니다.

### 2-2. **RDBMS, NoSQL**

데이터의 성격과 요구 사항에 따라 RDBMS는 정확성과 일관성이 중요한 구조화된 데이터 관리에, NoSQL은 유연성과 확장성이 요구되는 비구조화된 데이터 처리에 적합합니다. 

2005년 급성장 중인 페이스북의 경우, DB서버를 확장해야 하는 상황이었다면, RDBMS와 NoSQL의 조합을 사용했을 것으로 추측할 수 있습니다.

특히나 돈, 결제와 관련된 것들은 관계형 데이터 베이스를 적극 권장합니다.

1. **관계형 데이터베이스 사용** :
    - **사용자 정보 관리**: 사용자의 기본 정보, 연락처, 관계 상태 등의 정확하고 일관된 데이터 관리가 필요합니다.
    - **콘텐츠 저장**: 게시글, 사진, 동영상 등의 콘텐츠와 이에 대한 사용자 반응(좋아요, 댓글)을 체계적으로 저장하고 검색합니다.
    - **검색 기능**: 복잡한 쿼리를 통한 다양한 정보 검색과 데이터 분석에 적합합니다.
2. **비관계형 데이터베이스 사용** :
    - **사용자 행동 로그**: 사용자의 사이트 내 활동 로그, 클릭 패턴 등의 대규모 비구조화된 데이터를 효율적으로 수집하고 분석합니다.
    - **세션 관리**: 대량의 사용자 세션 데이터를 관리하는 데 NoSQL 데이터베이스의 빠른 읽기/쓰기 성능이 효과적입니다.
  
### 3-1. 수직적 규모확장 vs 수평적 규모확장

> 현재 서비스의 성능향상의 목표를 파악하고 계획한 뒤 스케일 업(scale up), 스케일 아웃(scale oup)중 적절한 우선순위를 정하며 확장하는것이 좋습니다.
> 
1. 스케일 업(Scale up) :
- 기존 서버의 CPU, 메모리 등의 고사양 자원을 추가 강화하는 방식입니다.
    - 장점: 관리가 단순하며 즉각적으로 시스템 성능을 향상시킬 수 있습니다.
    - 단점: 하드웨어의 물리적 한계와 비용 측면에서 확장에는 한계가 있으며, 단일 서버에 의존함으로써 서버 장애 시 전체 시스템의 가용성이 영향을 받을 수 있습니다.

**2.** 스케일 아웃(Scale out) :

- 새로운 서버를 추가하여 기존 시스템의 수평적 자원 확장을 추구하는 방식입니다.
    - 장점: 클라우드 서비스의 활용으로 트래픽에 따라 유동적으로 서버를 증설하거나 줄임으로써 비용을 효율화 할 수 있습니다. 다중화를 통해 시스템의 고가용성(High Availability)과 장애 대비(Failover) 능력을 향상시킬 수 있습니다.
    - 단점: 유동적으로 변하는 서버 환경을 관리해야 하며, 로드 밸런서를 통한 트래픽 분산 관리가 필요합니다.

수직적 규모 확장은 간단하게 시스템의 성능을 향상시킬 수 있는 방법이지만, 하드웨어의 한계,너무 많은 요청시 응답속도 저하, *단일 실패 지점(single point of failure)이라는 리스크를 갖습니다. 

반면, 수평적 규모 확장은 시스템의 확장성과 탄력성을 제공하며 클라우드 컴퓨팅의 이점을 최대화할 수 있습니다. 동시에 관리적 비용이 늘어납니다.

*단일 실패 지점(single point of failure, SPOF): 
시스템이 하나의 서버에 의존할 때, 그 서버에 문제가 생기면 전체 시스템이 중단될 수 있습니다. 이는 시스템의 전반적인 가용성과 신뢰성에 큰 영향을 미칩니다. 예를 들어, 서버의 하드웨어 결함, 소프트웨어 오류, 네트워크 문제 등이 발생할 경우, 모든 사용자가 영향을 받을 수 있습니다.

---

페이스북은 많은 사용자들이 짧은 글작성하고 그 글을보며, 좋아요, 댓글등을 보는 커뮤니케이션 서비스입니다. 그렇다면 페이스북이 서비스를 확장할 때, 수직적 확장도 중요하지만 우선적으로 많은 요청에도 문제없을  수평적규모확장인 스케일아웃을 우선적으로 고려했을 것입니다. 그리고 수평적 규모확장을 진행하면서 로드밸런서도 필수 고려사항이었을 것입니다.

### 3-2. 로드밸런서

> 로드 밸런서는 트래픽을 여러 서버에 분산시켜 각 서버에 대한 부하를 최소화하는 기능을 수행합니다. 그리고 사용자에게 더 빠른 응답시간을 제공합니다.
그리고 특정 서버에서 문제가 발생하면 로드밸런서는 해당 서버로의 트래픽을 차단하고 다른 서버로 트래픽을 전환해 가용성이 향상됩니다.
> 

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/43abd0ae-735e-4218-a0e8-8ee2927505ff/c0c77f6a-3be7-493b-8cf1-b9b3a572fdd7/Untitled.png)

- OSI(Open Systems Interconnection) 모델의 7계층
    1. 물리 계층(Physical Layer): 실제 전기적, 물리적 신호 전송이 일어나는 계층입니다.
    2. 데이터 링크 계층(Data Link Layer): 네트워크 기기 간의 데이터 전송을 담당하며, MAC 주소를 이용합니다.
    3. 네트워크 계층(Network Layer): 데이터 패킷의 라우팅을 담당하는 계층으로 IP 주소를 사용합니다.
    4. 전송 계층(Transport Layer): 두 장치 간의 데이터 전송을 관리하며, TCP/UDP 포트를 사용합니다.
    5. 세션 계층(Session Layer): 통신 세션을 설정, 유지, 종료하는 역할을 합니다.
    6. 표현 계층(Presentation Layer): 데이터의 표현 방식을 정의하고, 암호화 및 압축을 담당합니다.
    7. 응용 계층(Application Layer): 최종 사용자와 직접 상호작용하는 애플리케이션들의 계층으로, HTTP, FTP 등의 프로토콜이 여기에 해당합니다.

---

- **로드 밸런싱과 OSI 모델**
    - 로드 밸런싱은 주로 네트워크 계층(3계층)과 전송 계층(4계층)에서 이루어집니다.
    주로 3,4 계층에서 활발히 이루어지는건 네트워크 트래픽을 관리하는 데 있어 핵심적인 역할을 하기때문입니다.
    - 네트워크 계층(3계층) 로드 밸런싱: IP 주소를 기반으로 트래픽을 분산합니다. 라우터나 스위치와 같은 네트워크 장비가 이 역할을 수행합니다.
    - 전송 계층 로드 밸런싱(4계층): TCP/UDP 포트 번호를 기반으로 트래픽을 분산합니다. 이는 서버의 성능을 극대화하고 대역폭 병목 현상을 줄이는 데 도움이 됩니다.
    - 응용 계층(7계층)에서의 로드 밸런싱은 더 고도화된 분산 방식을 제공합니다.
    - 클라이언트 요청의 내용을 기반으로 서버를 선택하여, 예를 들어 HTTP 헤더, 쿠키, 세션 데이터 등을 분석하여 로드를 분산시킵니다.

---

- 로드 밸런싱 알고리즘 종류
    - 라운드 로빈 방식 (Round Robin Method):
        - 가장 간단한 로드 밸런싱 방식으로, 순서대로 순환하면서 요청을 서버에 분배합니다.
        - 예를 들어, 서버 A, B, C가 있으면 첫 번째 요청은 A에, 두 번째는 B에, 세 번째는 C에 분배하고, 그 다음 요청은 다시 A에 분배하는 식입니다.
        - 각 서버에 균등하게 트래픽을 분산시키지만, 서버의 실제 부하나 성능은 고려하지 않습니다.
    - 가중 라운드로빈 방식 (Weighted Round Robin Method):
        - 라운드 로빈 방식에 각 서버의 성능이나 용량을 고려한 가중치를 추가한 방식입니다.
        - 더 높은 성능을 가진 서버에 더 높은 가중치를 부여하여, 더 많은 요청을 처리하게 합니다.
        - 서버 간 성능 차이를 보다 효과적으로 관리할 수 있습니다.
    - IP 해시 방식 (IP Hash Method):
        - 클라이언트의 IP 주소를 해싱하여 특정 서버에 요청을 지속적으로 할당하는 방식입니다.
        - 사용자의 세션을 특정 서버에 고정시켜 일관된 서비스를 제공합니다.
        - 사용자가 동일한 서버와 지속적으로 연결되어야 하는 경우에 유용합니다.
    - 최소 연결 방식 (Least Connection Method):
        - 현재 활성 연결이 가장 적은 서버에 새 요청을 할당합니다.
        - 서버 간 부하가 불균등할 때 효과적으로 부하를 분산시킬 수 있습니다.
        - 동시에 많은 연결을 유지하는 서비스에 적합합니다.
    - 최소 응답시간 방식 (Least Response Time Method):
        - 서버의 응답 시간을 기준으로 가장 빠르게 응답할 수 있는 서버에 요청을 할당합니다.
        - 서버의 현재 성능과 응답 속도를 고려하여 최적의 서비스를 제공합니다.
        - 사용자 경험을 최적화하는 데 중요한 방법입니다.
    - 대역폭 방식 (Bandwidth Method):
        - 서버의 현재 사용 가능한 대역폭을 기준으로 요청을 분배합니다.
        - 대역폭이 넓은 서버에 더 많은 트래픽을 할당하여 네트워크 자원을 효율적으로 활용합니다.
        - 네트워크 집약적인 애플리케이션에 적합한 방식입니다.

### 3-3. 데이터베이스 다중화

> 데이터 베이스 다중화를 하지않으면 장애 발생시 해당 서비스는 장애처리까지 서비스 이용이 불가능해 진다.
여러개의 노드에 각자의 역할과 규칙을 정한 기본의 다중화 방식을 이용하면 좀 더 효율적인 DB관리가 가능하다.
> 

![스크린샷 2023-11-24 오후 11.27.27.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/43abd0ae-735e-4218-a0e8-8ee2927505ff/91ef325d-44b7-4a8c-8e5b-c1083a698ad7/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2023-11-24_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_11.27.27.png)

데이터베이스 다중화는 Source-Replica(이전에는 Master-Slave라고 불렸으나, 최근에는 부정적인 역사적 함의를 고려하여 Source-Replica로 더 많이 사용되고 있음) 구조로 이루어져 있습니다. 

- **Master**(**Source) 서버**: 데이터의 주된 쓰기(Write) 작업을 담당합니다.
- **Slave**(**Replica) 서버**: 주로 읽기(Read) 작업을 처리합니다. source 서버에서 사본을 전달받아 대부분의 애플리케이션에서 읽기 연산작업을 담당합니다.
- **트래픽 부하 대응**: Replica 서버를 확장하여 서버트래픽 부하에 대응합니다.
- **재해 복구**: 데이터베이스를 여러 지역에 분산시켜 자연재해나 전쟁과 같은 예상치 못한 상황에서도 데이터를 보호할 수 있습니다.
- **장애 대응**: Source 서버에 장애가 발생할 경우, Replica 서버 중 하나를 Source 서버로 승격시켜 장애 시간을 최소화합니다.
- **복제 지연**: 네트워크나 서버 상황에 따라 데이터 복제에 지연이 발생할 수 있습니다.

---

### 3-3. 데이터베이스 다중화 종류

**리플리케이션 (Replication)**

- **구조**: 마스터-슬래이브 구조로, 마스터 노드는 쓰기 작업을, 슬래이브 노드는 읽기 작업을 처리합니다. (마스터-슬래이브의 의미때문에 요즘은 Master → Source / Slave → replica 단어를 사용함)
- **동기화 방식**: 주로 비동기 방식을 사용합니다.
- **장점**:
    - 읽기 작업 위주의 시스템에서 성능 향상을 제공합니다.
    - 시스템의 고가용성을 지원하며, 데이터 백업 및 재해 복구에 유리합니다.
- **단점**:
    - 데이터 일관성이 떨어질 수 있으며, 특히 마스터 노드에 장애가 발생한 경우 복구가 어려울 수 있습니다.
    - 슬래이브 노드가 마스터 노드를 따라잡기까지 지연이 발생할 수 있습니다.
    

**클러스터링 (Clustering)**

- **구조**: 모든 노드가 읽기와 쓰기를 수행하는 수평적 구조입니다.
- **동기화 방식**: 주로 동기 방식을 사용하여 높은 데이터 일관성을 유지합니다.
- **장점**:
    - 높은 데이터 일관성과 장애 허용성을 제공합니다.
    - 한 노드가 실패해도 시스템 전체가 계속 운영될 수 있어 장애 복구에 유리합니다.
- **단점**:
    - 쓰기 작업에 대한 성능 저하가 발생할 수 있습니다.
    - 시스템 확장성에 한계가 있을 수 있으며, 장애가 전파될 위험이 있습니다.

---

**리플리케이션 (Replication) 종류**

1. 단일 마스터 리플리케이션:
    - 한 개의 마스터 노드가 모든 쓰기 작업을 처리하고, 
    여러 슬래이브 노드가 이를 복제하여 읽기 작업을 수행합니다.
    - 장점: 구성이 단순하고, 쓰기 작업에 대한 일관성을 유지하기 쉽습니다.
    - 단점: 마스터 노드에 장애가 발생하면 전체 시스템에 영향을 줄 수 있습니다.
2. 멀티 마스터 리플리케이션:
    - 여러 마스터 노드가 존재하여, 각각 쓰기 작업을 처리하고 서로의 데이터를 복제합니다.
    - 장점: 고가용성과 부하 분산이 가능하며, 한 노드의 장애가 전체 시스템에 미치는 영향을 줄일 수 있습니다.
    - 단점: 데이터 일관성 유지가 복잡해질 수 있으며, 충돌 해결 메커니즘이 필요합니다.
3. 체인 리플리케이션:
    - 슬래이브 노드가 다른 슬래이브 노드에게 데이터를 전달하는 체인 형태의 구성을 가집니다.
    - 장점: 마스터 노드에 대한 부하를 분산시킬 수 있습니다.
    - 단점: 데이터 전파에 따른 지연 시간이 증가할 수 있으며, 체인 중 한 노드의 장애가 전체 체인에 영향을 줄 수 있습니다.

---

**클러스터링 (Clustering) 종류**

1. Active-Active 클러스터링:
    - 모든 클러스터 노드가 활성 상태로 운영되며, 각 노드는 독립적으로 읽기 및 쓰기 작업을 수행합니다.
    - 장점: 높은 처리량과 빠른 응답 시간을 제공합니다. 또한, 한 노드의 장애가 발생해도 다른 노드가 작업을 계속 수행할 수 있어 고가용성을 지원합니다.
    - 단점: 데이터 동기화와 충돌 관리가 복잡할 수 있으며, 이는 시스템 설계와 운영에 추가적인 고려를 요구합니다.
2. Active-Standby 클러스터링:
    - 일부 노드가 활성 상태로 운영되고, 나머지 노드는 대기 상태로 유지됩니다. 활성 노드에 장애가 발생하면, 대기 노드가 활성화되어 작업을 이어받습니다.
    - 장점: 장애 발생 시 빠른 복구가 가능하며, 시스템의 전체적인 안정성을 향상시킵니다.
    - 단점: 대기 노드가 활성화되기 전까지의 지연 시간이 있을 수 있으며, 대기 노드의 유지 비용이 발생합니다.
3. Shared-Nothing 클러스터링:
    - 각 노드가 자체 저장소를 가지고 독립적으로 작동합니다. 데이터는 클러스터 내의 노드 간에 분산됩니다.
    - 장점: 높은 확장성과 장애 격리가 가능합니다. 한 노드의 장애가 다른 노드나 전체 클러스터에 영향을 미치지 않습니다.
    - 단점: 데이터 분산과 관리가 복잡하며, 전체 시스템의 일관성 유지가 도전적일 수 있습니다.
4. Shared-Disk 클러스터링:
    - 모든 노드가 공통의 저장소를 공유하면서 작동합니다. 이는 저장소 레벨에서 데이터 일관성을 유지합니다.
    - 장점: 데이터 관리가 단순화되며, 저장소 자원을 효율적으로 활용할 수 있습니다.
    - 단점: 공유 저장소에 대한 의존도가 높으며, 저장소의 성능이 전체 클러스터 성능에 큰 영향을 미칩니다.

---

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/43abd0ae-735e-4218-a0e8-8ee2927505ff/7fc9ddd9-df7b-44af-aed9-8709429d2a1d/Untitled.png)

현재의 페이스북과 같은 대규모 소셜 미디어 플랫폼의 경우, 데이터베이스 관리 전략으로서 리플리케이션과 클러스터링 모두 필요하고 중요합니다. 

하지만 초기 확장 단계에서는 리플리케이션과 클러스터링 중 특히 **리플리케이션**이 우선적으로 고려될 가능성이 높습니다. 

사용자가 확장됨에 따라, 읽기 요청이 증가하는 것이 일반적입니다. 리플리케이션을 사용하면 읽기 요청을 주 서버와 복제 서버로 분산시켜 처리할 수 있어, 전체 시스템의 읽기 성능을 향상시킬 수 있습니다.

전 세계 사용자에게 서비스를 제공하는 경우, 리플리케이션을 통해 각 지역에 데이터의 복제본을 배치함으로써 사용자에게 더 빠른 데이터 접근성을 제공할 수 있습니다.

이러한 이유로 우선적으로 리플리케이션을 고려했을 순 있지만, 최종적으로 많은 대규모 시스템에서는 리플리케이션과 클러스터링을 함께 사용하여 각각의 장점을 최대한 활용합니다. 

예를 들어, 데이터의 안전성과 가용성을 위해 리플리케이션을 사용하면서, 시스템의 전반적인 성능과 부하 분산을 위해 클러스터링을 적용하는 것입니다.

### 4-1. 캐시

> 캐시는 이전에 액세스한 데이터나 연산 결과를 저장하여 빠른 액세스를 제공합니다.
서버와 데이터베이스 중간에 위치시켜서 이전에 조회했던 데이터에 대해서는 데이터베이스에서 조회하지 않고, 캐시에서 바로 데이터를 가져와서 응답함으로써 데이터베이스의 부하를 줄일 수 있습니다.
> 

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/43abd0ae-735e-4218-a0e8-8ee2927505ff/30ca94d9-8aa2-4db4-8463-edb71bbfb160/Untitled.png)

**캐시 사용 시 유의할 점**

- **데이터 만료(Data Expiry)**: 캐시에 저장된 데이터는 적절한 만료 시간을 갖고, 데이터베이스의 변경 사항에 따라 갱신되어야 합니다. 이를 통해 데이터의 신선도를 보장하고, 사용자에게 일관된 정보를 제공합니다.
- **일관성(Consistency)**: 모든 사용자가 동일한 정보를 볼 수 있도록 캐시의 데이터는 데이터베이스의 내용과 일치해야 합니다. 데이터베이스와 캐시 간의 동기화를 관리하여 데이터 일관성을 유지합니다.
- **Eviction Policy (배출 정책)**: 캐시 메모리가 가득 찼을 때 어떤 데이터를 제거할지를 결정하는 규칙입니다. LRU, LFU, FIFO와 같은 다양한 배출 정책을 통해 캐시의 효율성을 극대화합니다.
- **단일 장애 지점 방지(SPOF Prevention)**: 캐시 시스템이 전체 시스템에 대한 단일 장애 지점이 되지 않도록 하여, 장애 발생 시에도 서비스가 지속될 수 있게 합니다. 이는 다중화 및 장애 복구 계획을 통해 달성됩니다.
- **과잉 프로비저닝 방지(Over-Provisioning Prevention)**: 필요 이상의 메모리를 할당하는 것을 방지하여 메모리 부족 현상을 예방합니다. 적절한 만료 정책과 배출 정책을 통해 메모리 사용을 최적화합니다.

페이스북과 같은 대규모 소셜 미디어 플랫폼에서는 캐시 시스템의 관리와 발전이 필수적이고 중요한 역할을 합니다.

초기에 페이스북과 같은 플랫폼에서는 사용자와 데이터의 급격한 증가에 따라 서버의 부하가 커집니다. 이 시기에 캐시를 활용하면 자주 접근되는 데이터(예: 인기 있는 게시물, 사용자 프로필)를 빠르게 제공하여 전체 시스템의 성능을 향상시킬 수 있습니다.

페이스북은 데이터의 신선도를 유지하면서 빠른 접근성을 제공하기 위해 정교한 만료 및 갱신 정책을 적용합니다. 동시에, 고가용성과 장애 허용을 위해 다중화된 캐시 시스템을 구축하여, 한 부분에 문제가 발생해도 전체 서비스에 영향을 미치지 않도록 했을것입니다.

따라서 페이스북과 같은 대규모 시스템에서는 초기에 캐시의 기본적인 활용을 시작으로, 시스템이 성장함에 따라 더욱 복잡하고 정교한 캐시 전략을 통합하여 시스템의 성능과 안정성을 극대화했을 것으로 추측합니다.

### 5-1. 콘텐츠 전송 네트워크(CDN)

> CDN (Content Delivery Network)은 정적 콘텐츠를 효율적으로 전송하기 위해 사용되는 지리적으로 분산된 서버 네트워크입니다. CDN의 주요 목적은 사용자에게 더 빠른 액세스를 제공하고 웹 서비스의 로딩 시간을 단축하는 것입니다.
> 

![스크린샷 2023-11-26 오후 3.33.19.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/43abd0ae-735e-4218-a0e8-8ee2927505ff/bd91e0d4-55eb-4149-9c39-26b5358e9eba/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2023-11-26_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_3.33.19.png)

![스크린샷 2023-11-26 오후 3.33.24.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/43abd0ae-735e-4218-a0e8-8ee2927505ff/702e1eec-3291-4d2e-b898-695354c30a68/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2023-11-26_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_3.33.24.png)

1. **CDN의 기본 원리:**
    - CDN은 지리적으로 분산된 서버 네트워크로 구성되어 있어, 정적 콘텐츠(이미지, 비디오, CSS, JavaScript 파일 등)를 캐싱하고 전송하는 데 사용됩니다.
    - 사용자가 웹사이트에 방문할 때, 가장 가까운 CDN 서버가 정적 콘텐츠를 전달하여 웹 페이지 로딩 시간을 단축시킵니다.
    - 사용자에게 필요한 콘텐츠가 CDN에 없는 경우, 원본 서버에서 콘텐츠를 가져와 CDN에 적재하고, 이후 요청에는 CDN을 통해 빠르게 제공합니다.
2. **콘텐츠 무효화 및 버전 관리:**
    - 콘텐츠 업데이트가 필요한 경우, CDN 서비스 제공업체가 제공하는 API를 사용하여 CDN에 저장된 콘텐츠를 무효화할 수 있습니다.
    - 오브젝트 버저닝을 이용하여 콘텐츠의 다른 버전을 서비스할 수 있습니다. 예를 들어, URL에 버전 번호를 추가하여 최신 버전의 콘텐츠를 제공할 수 있습니다.
3. **보안 강화:**
    - CDN은 DDoS 공격 방지 기능을 통해 서비스 중단을 방지하며, SSL/TLS 지원을 통해 데이터 전송 중 암호화를 제공합니다.
    - 웹 애플리케이션 방화벽과 같은 추가적인 보안 기능을 통해 웹사이트를 해킹 및 악성 활동으로부터 보호합니다.
4. **글로벌 도달 범위:**
    - CDN은 전 세계적으로 분산된 서버 네트워크를 활용, 사용자에게 빠른 콘텐츠 전송을 가능하게 합니다. 이는 국제적인 사용자 기반을 가진 콘텐츠 제공자에게 특히 유리합니다.
5. **비용 절감 및 성능 향상:**
    - CDN은 콘텐츠의 효율적인 배포를 통해 데이터 전송 비용과 대역폭 사용량을 줄일 수 있습니다.
    - 또한, CDN을 사용함으로써 웹사이트의 로딩 시간이 단축되어 사용자 경험을 개선할 수 있습니다.
6. **스케일링과 통합:**
    - CDN은 트래픽 변동에 따라 콘텐츠의 안정적인 배포를 지원합니다.
    - 많은 CDN 제공업체들은 콘텐츠 관리와 설정을 자동화하고 사용자 정의할 수 있는 API를 제공합니다.

CDN(Content Delivery Network)은 글로벌 서비스를 제공하는 웹사이트나 애플리케이션의 아키텍처 설계에서 중요한 네트워크 구성요소입니다.

### 6-1. **무상태(stateless) 웹 계층**

> 무상태 웹 계층(Stateless Web Layer)은 웹 개발에서 클라이언트와 서버 간의 상호작용이 특정 세션 또는 사용자 상태에 의존하지 않는 방식을 말합니다. 
HTTP는 기본적으로 무상태 프로토콜입니다. 각 요청은 독립적이며, 서버는 이전 요청이나 상태를 기억하지 않습니다.
> 

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/43abd0ae-735e-4218-a0e8-8ee2927505ff/5fd4b10f-cc32-471a-a4af-4e9f831290e7/Untitled.png)

---

### **무상태 웹 계층의 특징:**

1. **독립적인 요청들**: 각 HTTP 요청은 독립적이어서 이전의 요청이나 사용자의 상태 정보를 저장하거나 참조하지 않습니다.
2. **단순성과 확장성**: 서버가 상태 정보를 유지할 필요가 없기 때문에, 시스템은 보다 단순하고 확장성이 높습니다.
3. **세션 관리**: 상태를 유지해야 하는 경우, 쿠키나 세션 등의 기술을 통해 클라이언트 측에서 이를 관리합니다.
4. **비연결성**: 서버는 요청에 응답한 후 연결을 종료하므로, 많은 수의 클라이언트를 효율적으로 처리할 수 있습니다.

### **무상태 웹 계층의 단점:**

- **상태 정보 부재**: 상태 정보가 없어서, 모든 요청이 필요한 모든 정보를 포함해야 합니다. 이는 반복적인 데이터 전송을 초래할 수 있습니다.
- **기능 제한**: 일부 복잡한 어플리케이션에서는 상태 정보가 필요할 수 있어, 무상태 방식이 제한적일 수 있습니다.

### **적용 사례:**

- 대부분의 웹 서비스와 API는 HTTP 프로토콜을 사용하여 무상태 방식으로 통신합니다.
- RESTful API는 무상태성을 중요한 원칙으로 삼아 설계되었습니다.

---

### 무상태 (Stateless)

1. **서버의 역할**: 클라이언트로부터 요청을 받으면 그에 대한 응답만을 처리하고, 클라이언트의 상태를 저장하지 않습니다.
2. **세션 관리**: 클라이언트 측에서 쿠키 등을 사용해 세션 관리를 수행합니다.
3. **외부 저장소 활용**: 필요한 경우 외부 데이터베이스에 정보를 저장하여 관리합니다.
4. **통신 특성**: HTTP 통신에서 이전 클라이언트 상태를 기록하지 않고, 요청마다 새로운 연결을 수립하고 끊는 방식을 사용합니다.
5. **장점**: 서버의 확장성이 높아 대량의 트래픽에 대응하기 용이합니다.
6. **단점**: 매 요청마다 추가 정보를 전송해야 하므로 데이터 소모가 더 클 수 있습니다.

### 상태유지 (Stateful)

1. **서버의 상태 보존**: 클라이언트의 상태를 서버가 저장하고, 이전 요청과 연속성을 유지합니다.
2. **세션 활용**: 서버가 클라이언트의 상태 정보를 기억하여 유용하게 활용합니다.
3. **통신 방식**: 클라이언트 간 또는 서버에서 특정 클라이언트로 메시지 전송이 가능합니다.
4. **리소스 절약**: 서버에서 클라이언트 세션을 유지할 필요가 없을 때 서버 리소스를 절약할 수 있습니다.
5. **처리 능력 한계**: 한 서버가 처리할 수 있는 클라이언트 수에 제한이 있으며, 초과 시 새로운 클라이언트 처리가 지연될 수 있습니다.
6. **Stateless와의 비교**: Stateless는 순간적인 접속 요청 수를 기준으로 처리하므로, 더 많은 클라이언트 요청에 대응할 수 있습니다.
